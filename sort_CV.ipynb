{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For this project we need two libraries\n",
    "1. PyPDF2\n",
    "2. nltk\n",
    "\n",
    "if these libraries not installed you can install them from anaconda by conda install command, or pip install from terminal/cmd or from in a cell in jupyter notebook (following cell has an example)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install PyPDF2\n",
    "\n",
    "\n",
    "#importing necessart library\n",
    "import PyPDF2 as p2\n",
    "from nltk import flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'r', 'python', 'git', 'java'}\n",
      "50.0%\n"
     ]
    }
   ],
   "source": [
    "content = []\n",
    "token = []\n",
    "have_skills = []\n",
    "\n",
    "#these tools are the company requirement for a data scientist post\n",
    "tools = [\"python\", \"hadoop\", \"r\", \"sql\", \"apache\", \"spark\", \"java\", \"git\"]\n",
    "\n",
    "#read the pdf file. these file can ve renamed sequecial order and can be read in a for loop to get\n",
    "#multiple pdf score\n",
    "\n",
    "\n",
    "pdf = open(\"Abrar's_CV.pdf\", \"rb\")\n",
    "pdfr = p2.PdfFileReader(pdf)\n",
    "\n",
    "\n",
    "#appedning all the text from the pdf in a list, getNumPage() return the number of page\n",
    "#use this number of page as termination condition of loop\n",
    "for i in range(pdfr.getNumPages()):\n",
    "    page = pdfr.getPage(i)\n",
    "    content.append(page.extractText())\n",
    "    \n",
    "\n",
    "#spliting each sentences in words    \n",
    "for i in range(len(content)):\n",
    "    token.append(content[i].split())\n",
    "    \n",
    "\n",
    "#as we split words from different index content of a list, so spliting creates a new list with multiple list inside\n",
    "# we will flatten the list to get all the words in a single list\n",
    "\n",
    "token2 = flatten(token)\n",
    "for i in range(len(token2)):\n",
    "    for j in range(len(tools)):\n",
    "        #here before comparing keywords with company tools keyword we convert all of them into lower string\n",
    "        if tools[j].lower() in token2[i].lower():\n",
    "            have_skills.append(tools[j].lower())\n",
    "            \n",
    "#printing all the skills that matches with the company requirements            \n",
    "print(set(have_skills))\n",
    "\n",
    "#scoring the cv based on how much skills (actually keyword mentioned in CV) \n",
    "#this score can be customised with any weights for each skills and any equations\n",
    "\n",
    "score = len(set(have_skills))/len(tools)*100\n",
    "\n",
    "#and finally printing the score\n",
    "print(str(round(score, 2)) + \"%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Further work\n",
    "- CV name and score can be stored in a excel file \n",
    "- Sort the score based on accending order and approach the person who have heigher score\n",
    "- At least remove the person who have very low score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Shorticomings\n",
    "- There is some encoding problem, sometimes some CV gives zero score \n",
    "- So zero score CV should be handled carefully"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
